'0 for none, 1 for primary education (4th grade), 2 for 5th to 9th grade, 3 for secondary education, 4 for higher education',
'1 for less than 2 hours, 2 for 2 to 5 hours, 3 for 5 to 10 hours, 4 for more than 10 hours' )
df = data.frame('Variables' = variables, 'Type' = type, 'Description' = description, 'Possible Values' = possible)
kable(df) %>% kable_styling() %>% column_spec(4, width = "20em")
# Import data and extract required information
data = read.csv('student-mat.csv', sep = ';')
data = data[data$G3 > 0, ]
df = data.frame('G3' = data$G3,
'absences' = data$absences,
'failures' = data$failures,
'goout' = data$goout,
'studytime' = data$studytime)
ggplot(df, aes(x=factor(G3)))+
geom_bar(stat="count", width=0.7, fill="steelblue") +
ggtitle("Barplot of Students' Final Grade") +
xlab('Final grade') +
ylab("Frequency") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(df, aes(x=absences)) +
geom_histogram(binwidth = 2, fill='steelblue') +
ggtitle("Histogram of Students' absences") +
xlab('absences') +
ylab("Frequency") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(df, aes(x=factor(failures)))+
geom_bar(stat="count", width=0.7, fill="steelblue") +
ggtitle("Barplot of Students' Failures") +
xlab('Failures') +
ylab("Frequency") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(df, aes(x=factor(failures)))+
geom_bar(stat="count", width=0.7, fill="steelblue") +
ggtitle("Barplot of Students' Failures") +
xlab('Failures') +
ylab("Frequency") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(df, aes(x=factor(studytime)))+
geom_bar(stat="count", width=0.7, fill="steelblue") +
ggtitle("Barplot of Students' Study Time") +
xlab('Study Time') +
ylab("Frequency") +
theme(plot.title = element_text(hjust = 0.5))
cor_a = round(cor(df$G3, df$absences) , 3)
cor_f = round(cor(df$G3, df$failures), 3)
cor_g = round(cor(df$G3, df$goout), 3)
cor_s = round(cor(df$G3, df$studytime), 3)
df = data.frame('Variable' = c('absences', 'failures', 'goout', 'studytime'), 'Correlation with G3' = c(cor_a, cor_f, cor_g, cor_s))
kable(df) %>% kable_styling()
model1 = lm(G3 ~ G1 + G2, data = data)
summary(model1)$adj.r.squared
model2 = lm(G3 ~ studytime + failures, data = data)
summary(model2)$adj.r.squared
model3 = lm(G3 ~ failures, data = data)
summary(model3)$adj.r.squared
model4 = lm(G3 ~ failures + Medu + Fedu + goout + age + traveltime, data=data)
summary(model4)$adj.r.squared
model5 = lm(G3 ~ school + sex + Mjob + Fjob + studytime + failures +
schoolsup + famsup + paid + internet + goout + health + absences, data = data)
summary(model5)$adj.r.squared
model = lm(G3 ~ absences + activities + age + failures + Fedu +
goout + Medu + studytime + G1 + G2, data)
model = step(model, trace = 0)
round(coef(model), 3)
y_hat = predict(model)
y = data$G3
plot(y, y_hat, col = 'blue', pch = 20, xlab = 'Actual value', ylab = 'Predicted value',
xlim = c(0, 20), ylim = c(0, 20), main = 'Actual value vs. Predicted value')
abline(0, 1, col = 'red')
names = names(coef(model))[-1]
coefficients = round(unname(summary(model)$coefficients[-1, 1] ), 4)
errors = round(unname(summary(model)$coefficients[-1, 2] ), 4)
t_value = round(unname(summary(model)$coefficients[-1, 3] ), 4)
p_value = round(unname(summary(model)$coefficients[-1, 4] ), 4)
df = data.frame("Variables" = names, "Est Coefficients" = coefficients, "Errors" = errors, "t_value" = t_value, "p_value" = p_value)
kable(df) %>% kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
coefs = as.data.frame(summary(model)$coefficients[-1, 1:2])
names(coefs)[2] = 'se'
coefs$vars = rownames(coefs)
ggplot(coefs, aes(vars, Estimate)) +
geom_errorbar(aes(ymin=Estimate - 1.96*se, ymax=Estimate + 1.96*se), lwd=1, colour="red", width=0) +
geom_errorbar(aes(ymin=Estimate - se, ymax=Estimate + se), lwd=1.5, colour="blue", width=0) +
geom_point(size=2, pch=21, fill="yellow")
mean((predict(model, data) - data$G3)^2)
round(mean((predict(model, data) - data$G3)^2), 3)
library(ggplot2)
library(class)
library(knitr)
library(kableExtra)
library(ISLR)
library(glmnet)
library(dplyr)
library(caret)
library(tree)
library(randomForest)
library(gbm)
library(xgboost)
library(keras)
library(e1071)
knitr::opts_chunk$set(echo = TRUE)
variables = c('absences', 'activities', 'age', 'failures', 'Fedu', 'G1', 'G2', 'goout', 'Medu', 'studytime')
type = c('numeric', 'binary', rep('numeric', 8))
description = c('number of school absences',
'extracurricular activities',
'student’s age',
'number of past class failures',
'father’s education',
'first period grade',
'second period grade',
'going out with friends',
'mother’s education',
'weekly study time')
possible = c('from 0 to 93',
'yes or no',
'15 to 22',
'n for 1 <= n < 3, 3 for n >= 3',
'0 for none, 1 for primary education (4th grade), 2 for 5th to 9th grade, 3 for secondary education, 4 for higher education',
'from 0 to 20',
'from 0 to 20',
'from 1 for very low to 5 for very high',
'0 for none, 1 for primary education (4th grade), 2 for 5th to 9th grade, 3 for secondary education, 4 for higher education',
'1 for less than 2 hours, 2 for 2 to 5 hours, 3 for 5 to 10 hours, 4 for more than 10 hours' )
df = data.frame('Variables' = variables, 'Type' = type, 'Description' = description, 'Possible Values' = possible)
kable(df) %>% kable_styling() %>% column_spec(4, width = "20em")
# Import data and extract required information
data = read.csv('student-mat.csv', sep = ';')
data = data[data$G3 > 0, ]
df = data.frame('G3' = data$G3,
'absences' = data$absences,
'failures' = data$failures,
'goout' = data$goout,
'studytime' = data$studytime)
ggplot(df, aes(x=factor(G3)))+
geom_bar(stat="count", width=0.7, fill="steelblue") +
ggtitle("Barplot of Students' Final Grade") +
xlab('Final grade') +
ylab("Frequency") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(df, aes(x=absences)) +
geom_histogram(binwidth = 2, fill='steelblue') +
ggtitle("Histogram of Students' absences") +
xlab('absences') +
ylab("Frequency") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(df, aes(x=factor(failures)))+
geom_bar(stat="count", width=0.7, fill="steelblue") +
ggtitle("Barplot of Students' Failures") +
xlab('Failures') +
ylab("Frequency") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(df, aes(x=factor(failures)))+
geom_bar(stat="count", width=0.7, fill="steelblue") +
ggtitle("Barplot of Students' Failures") +
xlab('Failures') +
ylab("Frequency") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(df, aes(x=factor(studytime)))+
geom_bar(stat="count", width=0.7, fill="steelblue") +
ggtitle("Barplot of Students' Study Time") +
xlab('Study Time') +
ylab("Frequency") +
theme(plot.title = element_text(hjust = 0.5))
cor_a = round(cor(df$G3, df$absences) , 3)
cor_f = round(cor(df$G3, df$failures), 3)
cor_g = round(cor(df$G3, df$goout), 3)
cor_s = round(cor(df$G3, df$studytime), 3)
df = data.frame('Variable' = c('absences', 'failures', 'goout', 'studytime'), 'Correlation with G3' = c(cor_a, cor_f, cor_g, cor_s))
kable(df) %>% kable_styling()
model1 = lm(G3 ~ G1 + G2, data = data)
summary(model1)$adj.r.squared
model2 = lm(G3 ~ studytime + failures, data = data)
summary(model2)$adj.r.squared
model3 = lm(G3 ~ failures, data = data)
summary(model3)$adj.r.squared
model4 = lm(G3 ~ failures + Medu + Fedu + goout + age + traveltime, data=data)
summary(model4)$adj.r.squared
model5 = lm(G3 ~ school + sex + Mjob + Fjob + studytime + failures +
schoolsup + famsup + paid + internet + goout + health + absences, data = data)
summary(model5)$adj.r.squared
model = lm(G3 ~ absences + activities + age + failures + Fedu +
goout + Medu + studytime + G1 + G2, data)
model = step(model, trace = 0)
round(coef(model), 3)
y_hat = predict(model)
y = data$G3
plot(y, y_hat, col = 'blue', pch = 20, xlab = 'Actual value', ylab = 'Predicted value',
xlim = c(0, 20), ylim = c(0, 20), main = 'Actual value vs. Predicted value')
abline(0, 1, col = 'red')
names = names(coef(model))[-1]
coefficients = round(unname(summary(model)$coefficients[-1, 1] ), 4)
errors = round(unname(summary(model)$coefficients[-1, 2] ), 4)
t_value = round(unname(summary(model)$coefficients[-1, 3] ), 4)
p_value = round(unname(summary(model)$coefficients[-1, 4] ), 4)
df = data.frame("Variables" = names, "Est Coefficients" = coefficients, "Errors" = errors, "t_value" = t_value, "p_value" = p_value)
kable(df) %>% kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
coefs = as.data.frame(summary(model)$coefficients[-1, 1:2])
names(coefs)[2] = 'se'
coefs$vars = rownames(coefs)
ggplot(coefs, aes(vars, Estimate)) +
geom_errorbar(aes(ymin=Estimate - 1.96*se, ymax=Estimate + 1.96*se), lwd=1, colour="red", width=0) +
geom_errorbar(aes(ymin=Estimate - se, ymax=Estimate + se), lwd=1.5, colour="blue", width=0) +
geom_point(size=2, pch=21, fill="yellow")
round(mean((predict(model, data) - data$G3)^2), 3)
resid = summary(model)$residuals
ggplot(as.data.frame(resid), aes(x = resid)) +
geom_histogram(binwidth = 0.5, fill = "steelblue") +
ggtitle("Histogram of residuals") +
xlab('Residuals') +
ylab("Count") +
theme(plot.title = element_text(hjust = 0.5))
plot(data$G3, resid, xlab = 'Actual values', ylab = 'Residuals', col = 'blue',
main = 'Actual values vs. Residuals', ylim = c(-15, 15), pch = 20)
abline(h=0, col = 'red')
set.seed(2020)
index = createDataPartition(data$G3, p = 0.8, list = F)
train = data[index, ]
test = data[-index, ]
model = lm(G3 ~ absences + goout + G1 + G2, train)
predictions = predict(model, test)
round(mean((test$G3 - predictions)^2), 3)
names(data)
selected = c(26, 30, 31, 32)
set.seed(2020)
rand = sample(1:nrow(data), 0.8 * nrow(data))
train_dataset = data[rand, selected]
test_dataset = data[-rand, selected]
train_cl = data[rand, 33]
test_cl = data[-rand, 33]
mses = rep(0, 50)
set.seed(2020)
for (i in 1:50) {
model = knn(train_dataset, test_dataset, cl = train_cl, k = i)
model = as.numeric(model)
mses[i] = mean((test_cl - model)^2)
}
plot(mses, type = 'l', col = 'blue', xlab = '# of nearest neighbors', ylab = 'Mean squared errors',
main = '# of nearest neighbors vs. MSE')
which.min(mses)
mses[which.min(mses)]
model = lm(G3 ~ absences + goout + G1 + G2, data)
mean((data$G3 - predict(model))^2)
model = knn(train_dataset, test_dataset, cl = train_cl, k = 1)
model
as.numeric(model)
selected = c(26, 30, 31, 32)
set.seed(2020)
rand = sample(1:nrow(data), 0.8 * nrow(data))
train_dataset = data[rand, selected]
test_dataset = data[-rand, selected]
train_cl = data[rand, 33]
test_cl = data[-rand, 33]
mses = rep(0, 50)
set.seed(2020)
for (i in 1:50) {
model = knn(train_dataset, test_dataset, cl = train_cl, k = i)
model = as.numeric(levels(model))[model]
mses[i] = mean((test_cl - model)^2)
}
plot(mses, type = 'l', col = 'blue', xlab = '# of nearest neighbors', ylab = 'Mean squared errors',
main = '# of nearest neighbors vs. MSE')
which.min(mses)
mses[which.min(mses)]
model = lm(G3 ~ absences + goout + G1 + G2, data)
mean((data$G3 - predict(model))^2)
which.min(mses)
round(mses[which.min(mses)], 3)
library(ggplot2)
library(class)
library(knitr)
library(kableExtra)
library(ISLR)
library(glmnet)
library(dplyr)
library(caret)
library(tree)
library(randomForest)
library(gbm)
library(xgboost)
library(keras)
library(e1071)
knitr::opts_chunk$set(echo = TRUE)
variables = c('absences', 'activities', 'age', 'failures', 'Fedu', 'G1', 'G2', 'goout', 'Medu', 'studytime')
type = c('numeric', 'binary', rep('numeric', 8))
description = c('number of school absences',
'extracurricular activities',
'student’s age',
'number of past class failures',
'father’s education',
'first period grade',
'second period grade',
'going out with friends',
'mother’s education',
'weekly study time')
possible = c('from 0 to 93',
'yes or no',
'15 to 22',
'n for 1 <= n < 3, 3 for n >= 3',
'0 for none, 1 for primary education (4th grade), 2 for 5th to 9th grade, 3 for secondary education, 4 for higher education',
'from 0 to 20',
'from 0 to 20',
'from 1 for very low to 5 for very high',
'0 for none, 1 for primary education (4th grade), 2 for 5th to 9th grade, 3 for secondary education, 4 for higher education',
'1 for less than 2 hours, 2 for 2 to 5 hours, 3 for 5 to 10 hours, 4 for more than 10 hours' )
df = data.frame('Variables' = variables, 'Type' = type, 'Description' = description, 'Possible Values' = possible)
kable(df) %>% kable_styling() %>% column_spec(4, width = "20em")
# Import data and extract required information
data = read.csv('student-mat.csv', sep = ';')
data = data[data$G3 > 0, ]
df = data.frame('G3' = data$G3,
'absences' = data$absences,
'failures' = data$failures,
'goout' = data$goout,
'studytime' = data$studytime)
ggplot(df, aes(x=factor(G3)))+
geom_bar(stat="count", width=0.7, fill="steelblue") +
ggtitle("Barplot of Students' Final Grade") +
xlab('Final grade') +
ylab("Frequency") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(df, aes(x=absences)) +
geom_histogram(binwidth = 2, fill='steelblue') +
ggtitle("Histogram of Students' absences") +
xlab('absences') +
ylab("Frequency") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(df, aes(x=factor(failures)))+
geom_bar(stat="count", width=0.7, fill="steelblue") +
ggtitle("Barplot of Students' Failures") +
xlab('Failures') +
ylab("Frequency") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(df, aes(x=factor(failures)))+
geom_bar(stat="count", width=0.7, fill="steelblue") +
ggtitle("Barplot of Students' Failures") +
xlab('Failures') +
ylab("Frequency") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(df, aes(x=factor(studytime)))+
geom_bar(stat="count", width=0.7, fill="steelblue") +
ggtitle("Barplot of Students' Study Time") +
xlab('Study Time') +
ylab("Frequency") +
theme(plot.title = element_text(hjust = 0.5))
cor_a = round(cor(df$G3, df$absences) , 3)
cor_f = round(cor(df$G3, df$failures), 3)
cor_g = round(cor(df$G3, df$goout), 3)
cor_s = round(cor(df$G3, df$studytime), 3)
df = data.frame('Variable' = c('absences', 'failures', 'goout', 'studytime'), 'Correlation with G3' = c(cor_a, cor_f, cor_g, cor_s))
kable(df) %>% kable_styling()
model1 = lm(G3 ~ G1 + G2, data = data)
summary(model1)$adj.r.squared
model2 = lm(G3 ~ studytime + failures, data = data)
summary(model2)$adj.r.squared
model3 = lm(G3 ~ failures, data = data)
summary(model3)$adj.r.squared
model4 = lm(G3 ~ failures + Medu + Fedu + goout + age + traveltime, data=data)
summary(model4)$adj.r.squared
model5 = lm(G3 ~ school + sex + Mjob + Fjob + studytime + failures +
schoolsup + famsup + paid + internet + goout + health + absences, data = data)
summary(model5)$adj.r.squared
model = lm(G3 ~ absences + activities + age + failures + Fedu +
goout + Medu + studytime + G1 + G2, data)
model = step(model, trace = 0)
round(coef(model), 3)
y_hat = predict(model)
y = data$G3
plot(y, y_hat, col = 'blue', pch = 20, xlab = 'Actual value', ylab = 'Predicted value',
xlim = c(0, 20), ylim = c(0, 20), main = 'Actual value vs. Predicted value')
abline(0, 1, col = 'red')
names = names(coef(model))[-1]
coefficients = round(unname(summary(model)$coefficients[-1, 1] ), 4)
errors = round(unname(summary(model)$coefficients[-1, 2] ), 4)
t_value = round(unname(summary(model)$coefficients[-1, 3] ), 4)
p_value = round(unname(summary(model)$coefficients[-1, 4] ), 4)
df = data.frame("Variables" = names, "Est Coefficients" = coefficients, "Errors" = errors, "t_value" = t_value, "p_value" = p_value)
kable(df) %>% kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
coefs = as.data.frame(summary(model)$coefficients[-1, 1:2])
names(coefs)[2] = 'se'
coefs$vars = rownames(coefs)
ggplot(coefs, aes(vars, Estimate)) +
geom_errorbar(aes(ymin=Estimate - 1.96*se, ymax=Estimate + 1.96*se), lwd=1, colour="red", width=0) +
geom_errorbar(aes(ymin=Estimate - se, ymax=Estimate + se), lwd=1.5, colour="blue", width=0) +
geom_point(size=2, pch=21, fill="yellow")
round(mean((predict(model, data) - data$G3)^2), 3)
resid = summary(model)$residuals
ggplot(as.data.frame(resid), aes(x = resid)) +
geom_histogram(binwidth = 0.5, fill = "steelblue") +
ggtitle("Histogram of residuals") +
xlab('Residuals') +
ylab("Count") +
theme(plot.title = element_text(hjust = 0.5))
plot(data$G3, resid, xlab = 'Actual values', ylab = 'Residuals', col = 'blue',
main = 'Actual values vs. Residuals', ylim = c(-15, 15), pch = 20)
abline(h=0, col = 'red')
set.seed(2020)
index = createDataPartition(data$G3, p = 0.8, list = F)
train = data[index, ]
test = data[-index, ]
model = lm(G3 ~ absences + goout + G1 + G2, train)
predictions = predict(model, test)
round(mean((test$G3 - predictions)^2), 3)
x = model.matrix(G3 ~ ., data)[, -1]
y = data$G3
grid = 10^seq(10, -2, length = 100)
lasso_mod = glmnet(x, y, alpha = 1, lambda = grid)
x_train = model.matrix(G3 ~ ., train)[, -1]
x_test = model.matrix(G3 ~., test)[, -1]
y_train = train$G3
y_test = test$G3
set.seed(2020)
cv.out = cv.glmnet(x_train, y_train, alpha = 1)
bestlam = cv.out$lambda.min
round(bestlam, 3)
cv.out
plot(cv.out)
out = glmnet(x, y, alpha = 1)
plot(out, xvar = "lambda")
coefficients = predict(out, type = 'coefficients', s = bestlam)
remain = c(11, 34, 36, 39:42)
df = data.frame(coefficients[remain])
rownames(df) = rownames(coefficients)[remain]
colnames(df) = 'Coefficients'
kable(df)
predictions = predict(lasso_mod, s = cv.out$lambda.1se, newx = x_test)
round(mean((predictions - y_test)^2), 3)
ridge_mod = glmnet(x, y, alpha = 0, lambda = grid)
set.seed(2020)
cv.out = cv.glmnet(x_train, y_train, alpha = 0)
bestlam = cv.out$lambda.min
round(bestlam, 3)
cv.out
plot(cv.out)
out = glmnet(x, y, alpha = 0)
plot(out, xvar = "lambda")
coefficients = predict(out, type = 'coefficients', s = bestlam)
remain = c(7, 10, 22, 26, 41, 42)
df = data.frame(coefficients[remain])
rownames(df) = rownames(coefficients)[remain]
colnames(df) = 'Coefficients'
kable(df)
coefficients
round(coefficients, 3)
coefficients = round(predict(out, type = 'coefficients', s = bestlam), 3)
remain = c(7, 10, 22, 26, 41, 42)
df = data.frame(coefficients[remain])
rownames(df) = rownames(coefficients)[remain]
colnames(df) = 'Coefficients'
kable(df)
predictions = predict(ridge_mod, s = cv.out$lambda.1se, newx = x_test)
round(mean((predictions - y_test)^2), 3)
tree_train = train
tree_test = test
colnames(tree_train)[32] = "Second_Midterm"
colnames(tree_test)[32] = "Second_Midterm"
tree = tree(G3 ~ ., tree_train)
plot(tree)
text(tree)
predictions = predict(tree, newdata = tree_test)
round(mean((predictions - tree_test$G3)^2), 3)
cv.performance = cv.tree(tree)
plot(cv.performance$size, cv.performance$dev, type = 'b',
xlab = 'size', ylab = 'deviance', main = 'Tree size vs.Deviance')
predictions = model %>% predict(test_data)
train_labels = as.matrix(train[, "G3"])
train_data = as.matrix(train[!names(train) %in% c("G3") & names(train) %in% numerics])
test_labels = as.matrix(test[, "G3"])
test_data = as.matrix(test[!names(test) %in% c("G3") & names(train) %in% numerics])
train_data <- scale(train_data)
test_data <- scale(test_data)
model = keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu",
input_shape = dim(train_data)[2]) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 1)
model %>% compile(
loss = "mse",
optimizer = optimizer_rmsprop(),
metrics = list("mean_absolute_error")
)
early_stop = callback_early_stopping(monitor = "val_loss", patience = 20)
epochs = 200
set.seed(2020)
history = model %>% fit(
train_data,
train_labels,
epochs = epochs,
validation_split = 0.2,
callbacks = list(early_stop)
)
library(ggplot2)
plot(history, metrics = "mean_absolute_error", smooth = FALSE) +
coord_cartesian(ylim = c(0, 5))
predictions = model %>% predict(test_data)
mse_nn = round(mean((test_labels - predictions) ^ 2), 3)
mse_nn
models = c('OLS', 'Random Forest', 'Boosting (tuned)', 'Bagging', 'Lasso', "XGboost', 'Ridge', 'Boosting', 'Tree', 'KNN', 'Neural network')
)
models = c('OLS', 'Random Forest', 'Boosting (tuned)', 'Bagging', 'Lasso', "XGboost', 'Ridge', 'Boosting', 'Tree', 'KNN', 'Neural network')
models = c('OLS', 'Random Forest', 'Boosting (tuned)', 'Bagging', 'Lasso', 'XGboost', 'Ridge', 'Boosting', 'Tree', 'KNN', 'Neural network')
mses = c(0.663, 0.684, 0.695, 0.727, 0.735, 0.742, 0.753, 0.787, 1.102, 1.583, mse_nn)
df = data.frame("Model" = models, 'MSE' = mses)
kable(df)
models = c('OLS', 'Random Forest', 'Boosting (tuned)', 'Bagging', 'Lasso', 'XGboost', 'Ridge', 'Boosting', 'Tree', 'KNN', 'Neural network')
mses = c(0.663, 0.684, 0.695, 0.727, 0.735, 0.742, 0.753, 0.787, 1.102, 1.583, mse_nn)
df = data.frame("Model" = models, 'MSE' = mses)
kable(df)
kable(df) %>% kable_styling(position = "center")
model = lm(G3 ~ . - G2, data)
summary(model)
mean(predict(model, data) - data$G3)^2
mean((predict(model, data) - data$G3)^2)
model = lm(G3 ~ . - G1, data)
mean((predict(model, data) - data$G3)^2)
